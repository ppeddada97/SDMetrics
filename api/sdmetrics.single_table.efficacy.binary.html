

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>sdmetrics.single_table.efficacy.binary module &mdash; SDMetrics 0.3.0 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="sdmetrics.single_table.efficacy.mlefficacy module" href="sdmetrics.single_table.efficacy.mlefficacy.html" />
    <link rel="prev" title="sdmetrics.single_table.efficacy.base module" href="sdmetrics.single_table.efficacy.base.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> SDMetrics
          

          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../install.html#stable-release">Stable Release</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install.html#from-source">From Source</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quickstart</a></li>
</ul>
<p class="caption"><span class="caption-text">Resources</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="sdmetrics.html">API Reference</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="sdmetrics.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="sdmetrics.column_pairs.html">sdmetrics.column_pairs package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="sdmetrics.column_pairs.html#subpackages">Subpackages</a></li>
<li class="toctree-l4"><a class="reference internal" href="sdmetrics.column_pairs.html#submodules">Submodules</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="sdmetrics.multi_table.html">sdmetrics.multi_table package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="sdmetrics.multi_table.html#subpackages">Subpackages</a></li>
<li class="toctree-l4"><a class="reference internal" href="sdmetrics.multi_table.html#submodules">Submodules</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="sdmetrics.single_column.html">sdmetrics.single_column package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="sdmetrics.single_column.html#subpackages">Subpackages</a></li>
<li class="toctree-l4"><a class="reference internal" href="sdmetrics.single_column.html#submodules">Submodules</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="reference internal" href="sdmetrics.single_table.html">sdmetrics.single_table package</a><ul class="current">
<li class="toctree-l4 current"><a class="reference internal" href="sdmetrics.single_table.html#subpackages">Subpackages</a></li>
<li class="toctree-l4"><a class="reference internal" href="sdmetrics.single_table.html#submodules">Submodules</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="sdmetrics.timeseries.html">sdmetrics.timeseries package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="sdmetrics.timeseries.html#subpackages">Subpackages</a></li>
<li class="toctree-l4"><a class="reference internal" href="sdmetrics.timeseries.html#submodules">Submodules</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="sdmetrics.html#submodules">Submodules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="sdmetrics.base.html">sdmetrics.base module</a></li>
<li class="toctree-l3"><a class="reference internal" href="sdmetrics.demos.html">sdmetrics.demos module</a></li>
<li class="toctree-l3"><a class="reference internal" href="sdmetrics.goal.html">sdmetrics.goal module</a></li>
<li class="toctree-l3"><a class="reference internal" href="sdmetrics.utils.html">sdmetrics.utils module</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#types-of-contributions">Types of Contributions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#report-bugs">Report Bugs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#fix-bugs">Fix Bugs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#implement-features">Implement Features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#write-documentation">Write Documentation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#submit-feedback">Submit Feedback</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#get-started">Get Started!</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#pull-request-guidelines">Pull Request Guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#unit-testing-guidelines">Unit Testing Guidelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#tips">Tips</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#release-workflow">Release Workflow</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../contributing.html#release-candidates">Release Candidates</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../authors.html">Credits</a></li>
<li class="toctree-l1"><a class="reference internal" href="../history.html">History</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../history.html#v0-3-0-2021-03-30">v0.3.0 - 2021-03-30</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../history.html#issues-closed">Issues closed</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../history.html#v0-2-0-2021-02-24">v0.2.0 - 2021-02-24</a></li>
<li class="toctree-l2"><a class="reference internal" href="../history.html#v0-1-3-2021-02-13">v0.1.3 - 2021-02-13</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../history.html#id3">Issues closed</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../history.html#v0-1-2-2021-01-27">v0.1.2 - 2021-01-27</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../history.html#id5">Issues closed</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../history.html#v0-1-1-2020-12-30">v0.1.1 - 2020-12-30</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../history.html#id10">Issues closed</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../history.html#v0-1-0-2020-12-18">v0.1.0 - 2020-12-18</a></li>
<li class="toctree-l2"><a class="reference internal" href="../history.html#v0-0-4-2020-11-27">v0.0.4 - 2020-11-27</a></li>
<li class="toctree-l2"><a class="reference internal" href="../history.html#v0-0-3-2020-11-20">v0.0.3 - 2020-11-20</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../history.html#id14">Issues closed</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../history.html#v0-0-2-2020-08-08">v0.0.2 - 2020-08-08</a></li>
<li class="toctree-l2"><a class="reference internal" href="../history.html#v0-0-1-2020-06-26">v0.0.1 - 2020-06-26</a></li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">SDMetrics</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="sdmetrics.html">sdmetrics package</a> &raquo;</li>
        
          <li><a href="sdmetrics.single_table.html">sdmetrics.single_table package</a> &raquo;</li>
        
          <li><a href="sdmetrics.single_table.efficacy.html">sdmetrics.single_table.efficacy package</a> &raquo;</li>
        
      <li>sdmetrics.single_table.efficacy.binary module</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            
              <a href="https://github.com/sdv-dev/SDMetrics/blob/master/docs/api/sdmetrics.single_table.efficacy.binary.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="module-sdmetrics.single_table.efficacy.binary">
<span id="sdmetrics-single-table-efficacy-binary-module"></span><h1>sdmetrics.single_table.efficacy.binary module<a class="headerlink" href="#module-sdmetrics.single_table.efficacy.binary" title="Permalink to this headline">¶</a></h1>
<p>Base class for Efficacy metrics for single table datasets.</p>
<p><strong>Classes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#sdmetrics.single_table.efficacy.binary.BinaryAdaBoostClassifier" title="sdmetrics.single_table.efficacy.binary.BinaryAdaBoostClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BinaryAdaBoostClassifier</span></code></a></p></td>
<td><p>Binary AdaBoostClassifier Efficacy based metric.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sdmetrics.single_table.efficacy.binary.BinaryDecisionTreeClassifier" title="sdmetrics.single_table.efficacy.binary.BinaryDecisionTreeClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BinaryDecisionTreeClassifier</span></code></a></p></td>
<td><p>Binary DecisionTreeClassifier Efficacy based metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric" title="sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BinaryEfficacyMetric</span></code></a></p></td>
<td><p>Base class for Binary Classification Efficacy metrics.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sdmetrics.single_table.efficacy.binary.BinaryLogisticRegression" title="sdmetrics.single_table.efficacy.binary.BinaryLogisticRegression"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BinaryLogisticRegression</span></code></a></p></td>
<td><p>Binary LogisticRegression Efficacy based metric.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sdmetrics.single_table.efficacy.binary.BinaryMLPClassifier" title="sdmetrics.single_table.efficacy.binary.BinaryMLPClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BinaryMLPClassifier</span></code></a></p></td>
<td><p>Binary MLPClassifier Efficacy based metric.</p></td>
</tr>
</tbody>
</table>
<dl class="class">
<dt id="sdmetrics.single_table.efficacy.binary.BinaryAdaBoostClassifier">
<em class="property">class </em><code class="sig-prename descclassname">sdmetrics.single_table.efficacy.binary.</code><code class="sig-name descname">BinaryAdaBoostClassifier</code><a class="reference internal" href="../_modules/sdmetrics/single_table/efficacy/binary.html#BinaryAdaBoostClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sdmetrics.single_table.efficacy.binary.BinaryAdaBoostClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric" title="sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric</span></code></a></p>
<p>Binary AdaBoostClassifier Efficacy based metric.</p>
<p>This fits an AdaBoostClassifier to the synthetic data and
then evaluates it making predictions on the real data.</p>
<p><strong>Classes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#sdmetrics.single_table.efficacy.binary.BinaryAdaBoostClassifier.MODEL" title="sdmetrics.single_table.efficacy.binary.BinaryAdaBoostClassifier.MODEL"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MODEL</span></code></a></p></td>
<td><p>An AdaBoost classifier.</p></td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="sdmetrics.single_table.efficacy.binary.BinaryAdaBoostClassifier.MODEL">
<code class="sig-name descname">MODEL</code><a class="headerlink" href="#sdmetrics.single_table.efficacy.binary.BinaryAdaBoostClassifier.MODEL" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.ensemble._weight_boosting.AdaBoostClassifier</span></code></p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="sdmetrics.single_table.efficacy.binary.BinaryDecisionTreeClassifier">
<em class="property">class </em><code class="sig-prename descclassname">sdmetrics.single_table.efficacy.binary.</code><code class="sig-name descname">BinaryDecisionTreeClassifier</code><a class="reference internal" href="../_modules/sdmetrics/single_table/efficacy/binary.html#BinaryDecisionTreeClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sdmetrics.single_table.efficacy.binary.BinaryDecisionTreeClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric" title="sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric</span></code></a></p>
<p>Binary DecisionTreeClassifier Efficacy based metric.</p>
<p>This fits a DecisionTreeClassifier to the synthetic data and
then evaluates it making predictions on the real data.</p>
<p><strong>Classes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#sdmetrics.single_table.efficacy.binary.BinaryDecisionTreeClassifier.MODEL" title="sdmetrics.single_table.efficacy.binary.BinaryDecisionTreeClassifier.MODEL"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MODEL</span></code></a></p></td>
<td><p>A decision tree classifier.</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#sdmetrics.single_table.efficacy.binary.BinaryDecisionTreeClassifier.MODEL_KWARGS" title="sdmetrics.single_table.efficacy.binary.BinaryDecisionTreeClassifier.MODEL_KWARGS"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MODEL_KWARGS</span></code></a></p></td>
<td><p>dict() -&gt; new empty dictionary</p></td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="sdmetrics.single_table.efficacy.binary.BinaryDecisionTreeClassifier.MODEL">
<code class="sig-name descname">MODEL</code><a class="headerlink" href="#sdmetrics.single_table.efficacy.binary.BinaryDecisionTreeClassifier.MODEL" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.tree._classes.DecisionTreeClassifier</span></code></p>
</dd></dl>

<dl class="attribute">
<dt id="sdmetrics.single_table.efficacy.binary.BinaryDecisionTreeClassifier.MODEL_KWARGS">
<code class="sig-name descname">MODEL_KWARGS</code><em class="property"> = {'class_weight': 'balanced', 'max_depth': 15}</em><a class="headerlink" href="#sdmetrics.single_table.efficacy.binary.BinaryDecisionTreeClassifier.MODEL_KWARGS" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric">
<em class="property">class </em><code class="sig-prename descclassname">sdmetrics.single_table.efficacy.binary.</code><code class="sig-name descname">BinaryEfficacyMetric</code><a class="reference internal" href="../_modules/sdmetrics/single_table/efficacy/binary.html#BinaryEfficacyMetric"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="sdmetrics.single_table.efficacy.base.html#sdmetrics.single_table.efficacy.base.MLEfficacyMetric" title="sdmetrics.single_table.efficacy.base.MLEfficacyMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">sdmetrics.single_table.efficacy.base.MLEfficacyMetric</span></code></a></p>
<p>Base class for Binary Classification Efficacy metrics.</p>
<p><strong>Methods</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric.SCORER" title="sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric.SCORER"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SCORER</span></code></a>(y_pred, *[, labels, pos_label, …])</p></td>
<td><p>Compute the F1 score, also known as balanced F-score or F-measure.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric.normalize" title="sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric.normalize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">normalize</span></code></a>(raw_score)</p></td>
<td><p>Returns the <cite>raw_score</cite> as is, since it is already normalized.</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric.goal" title="sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric.goal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">goal</span></code></a></p></td>
<td><p>str(object=’’) -&gt; str</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric.max_value" title="sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric.max_value"><code class="xref py py-obj docutils literal notranslate"><span class="pre">max_value</span></code></a></p></td>
<td><p>int([x]) -&gt; integer</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric.min_value" title="sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric.min_value"><code class="xref py py-obj docutils literal notranslate"><span class="pre">min_value</span></code></a></p></td>
<td><p>int([x]) -&gt; integer</p></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric.SCORER">
<code class="sig-name descname">SCORER</code><span class="sig-paren">(</span><em class="sig-param">y_pred</em>, <em class="sig-param">*</em>, <em class="sig-param">labels=None</em>, <em class="sig-param">pos_label=1</em>, <em class="sig-param">average='binary'</em>, <em class="sig-param">sample_weight=None</em>, <em class="sig-param">zero_division='warn'</em><span class="sig-paren">)</span><a class="headerlink" href="#sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric.SCORER" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the F1 score, also known as balanced F-score or F-measure.</p>
<p>The F1 score can be interpreted as a weighted average of the precision and
recall, where an F1 score reaches its best value at 1 and worst score at 0.
The relative contribution of precision and recall to the F1 score are
equal. The formula for the F1 score is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">F1</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">precision</span> <span class="o">*</span> <span class="n">recall</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">precision</span> <span class="o">+</span> <span class="n">recall</span><span class="p">)</span>
</pre></div>
</div>
<p>In the multi-class and multi-label case, this is the average of
the F1 score of each class with weighting depending on the <code class="docutils literal notranslate"><span class="pre">average</span></code>
parameter.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_true</strong> (<em>1d array-like</em><em>, or </em><em>label indicator array / sparse matrix</em>) – Ground truth (correct) target values.</p></li>
<li><p><strong>y_pred</strong> (<em>1d array-like</em><em>, or </em><em>label indicator array / sparse matrix</em>) – Estimated targets as returned by a classifier.</p></li>
<li><p><strong>labels</strong> (<em>array-like</em><em>, </em><em>default=None</em>) – <p>The set of labels to include when <code class="docutils literal notranslate"><span class="pre">average</span> <span class="pre">!=</span> <span class="pre">'binary'</span></code>, and their
order if <code class="docutils literal notranslate"><span class="pre">average</span> <span class="pre">is</span> <span class="pre">None</span></code>. Labels present in the data can be
excluded, for example to calculate a multiclass average ignoring a
majority negative class, while labels not present in the data will
result in 0 components in a macro average. For multilabel targets,
labels are column indices. By default, all labels in <code class="docutils literal notranslate"><span class="pre">y_true</span></code> and
<code class="docutils literal notranslate"><span class="pre">y_pred</span></code> are used in sorted order.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.17: </span>Parameter <cite>labels</cite> improved for multiclass problem.</p>
</div>
</p></li>
<li><p><strong>pos_label</strong> (<em>str</em><em> or </em><em>int</em><em>, </em><em>default=1</em>) – The class to report if <code class="docutils literal notranslate"><span class="pre">average='binary'</span></code> and the data is binary.
If the data are multiclass or multilabel, this will be ignored;
setting <code class="docutils literal notranslate"><span class="pre">labels=[pos_label]</span></code> and <code class="docutils literal notranslate"><span class="pre">average</span> <span class="pre">!=</span> <span class="pre">'binary'</span></code> will report
scores for that label only.</p></li>
<li><p><strong>average</strong> (<em>{'micro'</em><em>, </em><em>'macro'</em><em>, </em><em>'samples'</em><em>,</em><em>'weighted'</em><em>, </em><em>'binary'}</em><em> or </em><em>None</em><em>,             </em><em>default='binary'</em>) – <p>This parameter is required for multiclass/multilabel targets.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the scores for each class are returned. Otherwise, this
determines the type of averaging performed on the data:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">'binary'</span></code>:</dt><dd><p>Only report results for the class specified by <code class="docutils literal notranslate"><span class="pre">pos_label</span></code>.
This is applicable only if targets (<code class="docutils literal notranslate"><span class="pre">y_{true,pred}</span></code>) are binary.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">'micro'</span></code>:</dt><dd><p>Calculate metrics globally by counting the total true positives,
false negatives and false positives.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">'macro'</span></code>:</dt><dd><p>Calculate metrics for each label, and find their unweighted
mean.  This does not take label imbalance into account.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">'weighted'</span></code>:</dt><dd><p>Calculate metrics for each label, and find their average weighted
by support (the number of true instances for each label). This
alters ‘macro’ to account for label imbalance; it can result in an
F-score that is not between precision and recall.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">'samples'</span></code>:</dt><dd><p>Calculate metrics for each instance, and find their average (only
meaningful for multilabel classification where this differs from
<code class="xref py py-func docutils literal notranslate"><span class="pre">accuracy_score()</span></code>).</p>
</dd>
</dl>
</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like of shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – Sample weights.</p></li>
<li><p><strong>zero_division</strong> (<em>&quot;warn&quot;</em><em>, </em><em>0</em><em> or </em><em>1</em><em>, </em><em>default=&quot;warn&quot;</em>) – Sets the value to return when there is a zero division, i.e. when all
predictions and labels are negative. If set to “warn”, this acts as 0,
but warnings are also raised.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>f1_score</strong> – F1 score of the positive class in binary classification or weighted
average of the F1 scores of each class for the multiclass task.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float or array of float, shape = [n_unique_labels]</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><code class="xref py py-meth docutils literal notranslate"><span class="pre">fbeta_score()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">precision_recall_fscore_support()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">jaccard_score()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">multilabel_confusion_matrix()</span></code></p>
</div>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id1"><span class="brackets">1</span></dt>
<dd><p><a class="reference external" href="https://en.wikipedia.org/wiki/F1_score">Wikipedia entry for the F1-score</a>.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="go">0.26...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="go">0.33...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>
<span class="go">0.26...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="go">array([0.8, 0. , 0. ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">1.0...</span>
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>When <code class="docutils literal notranslate"><span class="pre">true</span> <span class="pre">positive</span> <span class="pre">+</span> <span class="pre">false</span> <span class="pre">positive</span> <span class="pre">==</span> <span class="pre">0</span></code>, precision is undefined.
When <code class="docutils literal notranslate"><span class="pre">true</span> <span class="pre">positive</span> <span class="pre">+</span> <span class="pre">false</span> <span class="pre">negative</span> <span class="pre">==</span> <span class="pre">0</span></code>, recall is undefined.
In such cases, by default the metric will be set to 0, as will f-score,
and <code class="docutils literal notranslate"><span class="pre">UndefinedMetricWarning</span></code> will be raised. This behavior can be
modified with <code class="docutils literal notranslate"><span class="pre">zero_division</span></code>.</p>
</dd></dl>

<dl class="attribute">
<dt id="sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric.goal">
<code class="sig-name descname">goal</code><em class="property"> = 'maximize'</em><a class="headerlink" href="#sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric.goal" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric.max_value">
<code class="sig-name descname">max_value</code><em class="property"> = 1</em><a class="headerlink" href="#sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric.max_value" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric.min_value">
<code class="sig-name descname">min_value</code><em class="property"> = 0</em><a class="headerlink" href="#sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric.min_value" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric.name">
<code class="sig-name descname">name</code><em class="property"> = None</em><a class="headerlink" href="#sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric.name" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric.normalize">
<em class="property">classmethod </em><code class="sig-name descname">normalize</code><span class="sig-paren">(</span><em class="sig-param">raw_score</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/sdmetrics/single_table/efficacy/binary.html#BinaryEfficacyMetric.normalize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric.normalize" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the <cite>raw_score</cite> as is, since it is already normalized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>raw_score</strong> (<em>float</em>) – The value of the metric from <cite>compute</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The normalized value of the metric</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="sdmetrics.single_table.efficacy.binary.BinaryLogisticRegression">
<em class="property">class </em><code class="sig-prename descclassname">sdmetrics.single_table.efficacy.binary.</code><code class="sig-name descname">BinaryLogisticRegression</code><a class="reference internal" href="../_modules/sdmetrics/single_table/efficacy/binary.html#BinaryLogisticRegression"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sdmetrics.single_table.efficacy.binary.BinaryLogisticRegression" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric" title="sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric</span></code></a></p>
<p>Binary LogisticRegression Efficacy based metric.</p>
<p>This fits a LogisticRegression to the synthetic data and
then evaluates it making predictions on the real data.</p>
<p><strong>Classes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#sdmetrics.single_table.efficacy.binary.BinaryLogisticRegression.MODEL" title="sdmetrics.single_table.efficacy.binary.BinaryLogisticRegression.MODEL"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MODEL</span></code></a></p></td>
<td><p>Logistic Regression (aka logit, MaxEnt) classifier.</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#sdmetrics.single_table.efficacy.binary.BinaryLogisticRegression.MODEL_KWARGS" title="sdmetrics.single_table.efficacy.binary.BinaryLogisticRegression.MODEL_KWARGS"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MODEL_KWARGS</span></code></a></p></td>
<td><p>dict() -&gt; new empty dictionary</p></td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="sdmetrics.single_table.efficacy.binary.BinaryLogisticRegression.MODEL">
<code class="sig-name descname">MODEL</code><a class="headerlink" href="#sdmetrics.single_table.efficacy.binary.BinaryLogisticRegression.MODEL" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.linear_model._logistic.LogisticRegression</span></code></p>
</dd></dl>

<dl class="attribute">
<dt id="sdmetrics.single_table.efficacy.binary.BinaryLogisticRegression.MODEL_KWARGS">
<code class="sig-name descname">MODEL_KWARGS</code><em class="property"> = {'class_weight': 'balanced', 'max_iter': 50, 'n_jobs': 2, 'solver': 'lbfgs'}</em><a class="headerlink" href="#sdmetrics.single_table.efficacy.binary.BinaryLogisticRegression.MODEL_KWARGS" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="sdmetrics.single_table.efficacy.binary.BinaryMLPClassifier">
<em class="property">class </em><code class="sig-prename descclassname">sdmetrics.single_table.efficacy.binary.</code><code class="sig-name descname">BinaryMLPClassifier</code><a class="reference internal" href="../_modules/sdmetrics/single_table/efficacy/binary.html#BinaryMLPClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sdmetrics.single_table.efficacy.binary.BinaryMLPClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric" title="sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">sdmetrics.single_table.efficacy.binary.BinaryEfficacyMetric</span></code></a></p>
<p>Binary MLPClassifier Efficacy based metric.</p>
<p>This fits a MLPClassifier to the synthetic data and
then evaluates it making predictions on the real data.</p>
<p><strong>Classes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#sdmetrics.single_table.efficacy.binary.BinaryMLPClassifier.MODEL" title="sdmetrics.single_table.efficacy.binary.BinaryMLPClassifier.MODEL"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MODEL</span></code></a></p></td>
<td><p>Multi-layer Perceptron classifier.</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#sdmetrics.single_table.efficacy.binary.BinaryMLPClassifier.MODEL_KWARGS" title="sdmetrics.single_table.efficacy.binary.BinaryMLPClassifier.MODEL_KWARGS"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MODEL_KWARGS</span></code></a></p></td>
<td><p>dict() -&gt; new empty dictionary</p></td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="sdmetrics.single_table.efficacy.binary.BinaryMLPClassifier.MODEL">
<code class="sig-name descname">MODEL</code><a class="headerlink" href="#sdmetrics.single_table.efficacy.binary.BinaryMLPClassifier.MODEL" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.neural_network._multilayer_perceptron.MLPClassifier</span></code></p>
</dd></dl>

<dl class="attribute">
<dt id="sdmetrics.single_table.efficacy.binary.BinaryMLPClassifier.MODEL_KWARGS">
<code class="sig-name descname">MODEL_KWARGS</code><em class="property"> = {'hidden_layer_sizes': (50,), 'max_iter': 50}</em><a class="headerlink" href="#sdmetrics.single_table.efficacy.binary.BinaryMLPClassifier.MODEL_KWARGS" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="sdmetrics.single_table.efficacy.mlefficacy.html" class="btn btn-neutral float-right" title="sdmetrics.single_table.efficacy.mlefficacy module" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="sdmetrics.single_table.efficacy.base.html" class="btn btn-neutral float-left" title="sdmetrics.single_table.efficacy.base module" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020, MIT Data To AI Lab.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>